# Deep Learning Project Template

A clean, modular, and extensible deep learning project template built with PyTorch. Designed for training, evaluating, and experimenting with classification tasks (extendable to others).

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ base.yaml         # All training & testing config (backbone, optimizer, scheduler, etc.)
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ (external datasets managed here, gitignored)
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ exp_YYYY_MM_DD_HHMM/   # Contains init.pth, best.pth, latest.pth, config backup
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backbone/
â”‚   â”‚   â””â”€â”€ resnet.py      # ResNet family implementation (18, 34, 50, 101, 152)
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ cifar10.py     # CIFAR10 loader with transforms
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluators/
â”‚   â”‚   â”œâ”€â”€ base_evaluator.py
â”‚   â”‚   â””â”€â”€ classification_evaluator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ classification.py
â”‚   â”‚
â”‚   â”œâ”€â”€ optimizers/
â”‚   â”‚   â””â”€â”€ factory.py     # Optimizer builder
â”‚   â”‚
â”‚   â”œâ”€â”€ schedulers/
â”‚   â”‚   â””â”€â”€ factory.py     # Scheduler builder
â”‚   â”‚
â”‚   â”œâ”€â”€ trainers/
â”‚   â”‚   â”œâ”€â”€ base_trainer.py
â”‚   â”‚   â””â”€â”€ classification_trainer.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ main.py               # Entry point for training
â”œâ”€â”€ evaluate.py           # Entry point for testing
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Train

```bash
python main.py --config configs/base.yaml
```

### 3. Evaluate

```bash
python evaluate.py --config configs/base.yaml --checkpoint experiments/exp_xxx/best.pth
```

---

## âš™ï¸ Key Features

* ğŸ”§ **Backbone modifiability**: Clean ResNet support with custom block extension
* âš¡ **Training/evaluation separation** with evaluator callback
* ğŸ§ª **Configurable with Hydra/YAML**: all training params, schedulers, and augmentations controlled from config
* ğŸ§µ **Checkpointing**: saves init, best, latest weights in structured folders
* ğŸ” **Resume training support**
* ğŸ“Š **Logging**: minimal custom logger
* ğŸ“‚ **Experiments are fully tracked and reproducible**

---

## ğŸ”„ TODO / Extensions

- [x] Design project structure and directories. (src, configs, experiments, etc.)
- [x] Implement ResNet backbone. (18, 34, 50, 101, 152)
- [x] Define classification trainer and evaluator.
- [x] Implement CIFAR10 dataset loader with data augmentation transforms with config.
- [x] Define logger utility and integrate with trainer/evaluator.
- [x] Define optimizer & scheduler and link with config.
- [x] Add checkpoint (init, best, latest checkpoints) saving/loading functionality.
- [x] Add a simple training progress UI (e.g., tqdm or custom console visualization).
- [ ] Add wandb or tensorboard support.
- [ ] Unit tests for trainer and evaluator.
- [ ] CLI with argparse or click.

---

## ğŸ“Œ Notes

* To add a new model: add under `src/backbone/`, modify `build_resnet()` or add new builder
* To add a new dataset: follow the `src/data/cifar10.py` structure
* `configs/base.yaml` is the unified config entry point. You can split it later into train/test if needed.

---

## ğŸ“¬ Contact (TBD)

Author: \[Your Name]
Email: \[[your\_email@example.com](mailto:your_email@example.com)]

Feel free to open issues or submit pull requests!
